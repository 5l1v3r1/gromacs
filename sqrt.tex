\section{Computation of the 1.0/sqrt function.}
\label{sec:sqrt}
\subsection{Introduction.}
The {\gromacs} project started with the development of a 
$1/\sqrt{x}$ processor which calculates
\begin{equation}
Y(x) = \frac{1}{ \sqrt{x} }
\end{equation}
As the project continued, the {\intel} processor was used to implement
{\gromacs}, which now turned into almost a full software project.
The $1/\sqrt{x}$ processor was implemented using a Newton-Raphson iteration 
scheme for one step. For this it needed lookup tables to provide the initial 
approximation. The $1/\sqrt{x}$ function makes it possible to use two almost 
independent tables for the exponent seed and the fraction seed with the IEEE 
floating point representation.

\subsection{Calculation of the SQRT function ...}
According to~\cite{Bekker87} the $1/\sqrt{x}$ can be calculated using
the Newton-Raphson iteration scheme. The inverse function is
\begin{equation}
X(y) = \frac{1}{y^{2}}
\end{equation}
So instead of calculating
\begin{equation}
Y(a) = q
\end{equation}
the equation
\begin{equation}
X(q) - a = 0
\label{eq:inversef}
\end{equation}
can now be solved using Newton-Raphson. An iteration is performed by
calculating
\begin{equation}
y_{n+1} = y_{n} - \frac{f(y_{n})}{f'(y_{n})}
\label{eq:nr}
\end{equation}
The absolute error $\varepsilon$, in this approximation is defined by
\begin{equation}
\varepsilon \equiv y_{n} - q
\end{equation}
using Taylor series expansion to estimate the error results in
\begin{equation}
\varepsilon _{n+1} = - \frac{\varepsilon _{n}^{2}}{2}
                       \frac{ f''(y_{n})}{f'(y_{n})}
\label{eq:taylor}
\end{equation}
according to~\cite{Bekker87} equation (3.2). This is an estimation of the
absolute error.

\subsection{... applied to floating point numbers}
Floating point numbers in IEEE 32 bit single precision format have a nearly
constant relative error of $\Delta x / x = 2^{-24}$. As seen earlier in the
Taylor series expansion equation (\ref{eq:taylor}), the error in every
iteration step is absolute and in general dependent of $y$. If the error is
expressed as a relative error $\varepsilon_{r}$ the following holds
\begin{equation}
\varepsilon _{{r}_{n+1}} \equiv \frac{\varepsilon_{n+1}}{y}
\end{equation}
and so
\begin{equation}
\varepsilon _{{r}_{n+1}} =
- ( \frac{\varepsilon _{n}}{y} )^{2} y \frac{ f''}{2f'}
\end{equation}
for the function $f(y) = y^{-2}$ the term $y f''/2f'$ is constant (equal
to $-3/2$) so the relative error $\varepsilon _{r_{n}}$ is independent of $y$.
\begin{equation}
\varepsilon _{{r}_{n+1}} =
\frac{3}{2} (\varepsilon_{r_{n}})^{2}
\label{eq:epsr}
\end{equation}

The conclusion of this is that the function $1/\sqrt{x}$ can be
calculated with a specified accuracy.

\begin{figure}
\begin{center}
\input{ieee}
\end{center}
\caption{IEEE single precision floating point format}
\label{fig:ieee}
\end{figure}

\subsection{Specification of the lookup table}
To calculate the function $1/\sqrt{x}$ using the previously mentioned
iteration scheme, it is clear that the first estimation of the solution must
be accurate enough to get precise results. The requirements for the
calculation are
\begin{itemize}
\item Maximum possible accuracy with the used IEEE format
\item Use only one iteration step for maximum speed
\end{itemize}

The first requirement states that the result of $1/\sqrt{x}$ may have a
relative error $\varepsilon_{r}$ equal to the $\varepsilon_{r}$ of a IEEE 32
bit single precision floating point number. From this the $1/\sqrt{x}$
of the initial approximation can be derived, rewriting the definition of
the relative error for succeeding steps, equation (\ref{eq:epsr})
\begin{equation}
\frac{\varepsilon_{n}}{y} =
\sqrt{\varepsilon_ {r_{n+1}} \frac{2f'}{yf''}}
\end{equation}
So for the lookup table the needed accuracy is
\begin{equation}
\frac{\Delta Y}{Y} = \sqrt{\frac{2}{3} 2^{-24}}
\label{eq:accy}
\end{equation}
which defines the width of the table that must be $\geq 13$ bit.

At this point the relative error $\varepsilon_{r_{n}}$ of the lookup table
is known. From this the maximum relative error in the argument can be 
calculated as follows. The absolute error
$\Delta x$ is defined as
\begin{equation}
\Delta x \equiv \frac{\Delta Y}{Y'}
\end{equation}
and thus
\begin{equation}
\frac{\Delta x}{Y} = \frac{\Delta Y}{Y} (Y')^{-1}
\end{equation}
and thus
\begin{equation}
\Delta x = constant \frac{Y}{Y'}
\end{equation}
for the $1/\sqrt{x}$ function $Y / Y' \sim x$ holds, so
$\Delta x / x = constant$. This is a property of the used floating point
representation as earlier mentioned. The needed accuracy of the argument of the
lookup table follows from
\begin{equation}
\frac{\Delta x}{x} = -2 \frac{\Delta Y}{Y}
\end{equation}
so, using the floating point accuracy, equation (\ref{eq:accy})
\begin{equation}
\frac{\Delta x}{x} = -2 \sqrt{\frac{2}{3} 2^{-24}}
\end{equation}
This defines the length of the lookup table which should be $\geq 12$ bit.

\subsection{Separate exponent and fraction computation}
The used IEEE 32 bit single precision floating point format specifies
that a number is represented by a exponent and a fraction. The previous 
section specifies for every possible floating point number the lookup table 
length and width. Only the size of the fraction of a floating point number 
defines the accuracy. The conclusion from this can be that the size of the 
lookup table is length of lookup table, earlier specified, times the size of 
the exponent ($2^{12}2^{8}, 1Mb$). The $1/\sqrt{x}$  function has the 
property that the exponent is independent of the fraction. This becomes clear 
if the floating point representation is used. Define
\begin{equation}
x \equiv (-1)^{S}(2^{E-127})(1.F)
\label{eq:fpdef}
\end{equation}
see fig. (\ref{fig:ieee}) where $0 \leq S \leq 1$, $0 \leq E \leq 255$,
$1 \leq 1.F < 2$ and $S$, $E$, $F$ integer (normalisation conditions). 
The sign bit ($S$) can be ommitted because $1/\sqrt{x}$ is only defined 
for $x > 0$. The $1/\sqrt{x}$ function applied to $x$ results in
\begin{equation}
y(x) = \frac{1}{\sqrt{x}}
\end{equation}
or
\begin{equation}
y(x) = \frac{1}{\sqrt{(2^{E-127})(1.F)}}
\end{equation}
this can be rewritten as
\begin{equation}
y(x) = (2^{E-127})^{-1/2}(1.F)^{-1/2}
\label{eq:yx}
\end{equation}
Define
\begin{equation}
(2^{E'-127}) \equiv (2^{E-127})^{-1/2}
\end{equation}
\begin{equation}
1.F'\equiv (1.F)^{-1/2}
\end{equation}
then $\frac{1}{\sqrt{2}} < 1.F' \leq 1$ holds, so the condition
$1 \leq 1.F' < 2$ which is essential for normalised real representation is
not valid anymore. By introducing an extra term this can be corrected.
Rewrite the $1/\sqrt{x}$ function applied to floating point numbers, equation
(\ref{eq:yx}) as
\begin{equation}
y(x) = (2^{\frac{127-E}{2}-1}) (2(1.F)^{-1/2})
\end{equation}
and
\begin{equation}
(2^{E'-127}) \equiv (2^{\frac{127-E}{2}-1})
\label{eq:exp}
\end{equation}
\begin{equation}
1.F'\equiv 2(1.F)^{-1/2}
\label{eq:frac}
\end{equation}
then $\sqrt{2} < 1.F \leq 2$ holds. This is not the exact valid range as
defined for normalised floating point numbers in equation (\ref{eq:fpdef}). 
The value $2$  causes the problem. By mapping this value on the nearest
representation $< 2$ this can be solved. The small error that is introduced
by this approximation is within the allowable range. 

The integer representation of the exponent is the next problem. Calculating
$(2^{\frac{127-E}{2}-1})$ introduces a fractional result if $(127-E) = odd$.
This is again easily accounted for by splitting up the calculation into an
odd and an even part. For $(127-E) = even$ $E'$ in equation (\ref{eq:exp})
can be exactly calculated in integer arithmetic as a function of $E$.
\begin{equation}
E' = \frac{127-E}{2} + 126
\end{equation}

For $(127-E) = odd$ equation (\ref{eq:yx}) can be rewritten as
\begin{equation}
y(x) = (2^{\frac{127-E-1}{2}})(\frac{1.F}{2})^{-1/2}
\end{equation}
thus
\begin{equation}
E' = \frac{126-E}{2} + 127
\end{equation}
which also can be calculated exactly in integer arithmetic.
Note that the fraction is automatically corrected for its range earlier
mentioned, so the exponent does not need an extra correction.

The conclusions from this are:
\begin{itemize}
\item The fraction and exponent lookup table are independent. The fraction
lookuptable exists of two tables (odd and even exponent) so the odd/even
information of the exponent (lsb bit) has to be used to select the right
table.
\item The exponent table is an 256 x 8 bit table, initialised for $odd$
and $even$.% as specified before
\end{itemize}

\subsection{Implementation}
The lookup tables can be generated by a small C program, which uses
floating point numbers and operations with IEEE 32 bit single precision format.
Note that because of the $odd$/$even$ information that is needed, the
fraction table is twice the size earlier specified (13 bit i.s.o. 12 bit).
%Fig. (\ref{fig:expgen}) in the appendix shows how to fill the exponent table,
%fig. (\ref{fig:fractgen}) shows how to fill the fraction table.

The function according to equation (\ref{eq:nr}) has to be implemented. 
Applied to the $1/\sqrt{x}$ function, equation 
(\ref{eq:inversef}) leads to
\begin{equation}
f = a - \frac{1}{y^{2}}
\end{equation}
and so
\begin{equation}
f' = \frac{2}{y^{3}}
\end{equation}
so
\begin{equation}
y_{n+1} = y_{n} - \frac{ a - \frac{1}{y^{2}_{n}} }{ \frac{2}{y^{3}_{n}} }
\end{equation}
or
\begin{equation}
y_{n+1} = \frac{y_{n}}{2} (3 - a y^{2}_{n})
\end{equation}
Where $y_{0}$ can be found in the lookup tables, and $y_{1}$ gives the result
to the maximum accuracy. 
%In fig. (\ref{fig:as_implementation}) the assembler implementation is given. 
It is clear that only one iteration extra (in double 
precision) is needed for a double precicion result.
